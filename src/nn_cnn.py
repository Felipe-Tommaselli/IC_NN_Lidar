#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
This script describe a convolutional network, that will be used to infer the angle and the distance in
the image generated by the lidar data. Note that the label of the images were generated manually with help
of the UI generated by the script lidar_tag.py.  

create a neural network with convolutional layers in Python with the Pytorch framework, the scripts must follow the following instructions:
1. It receives images through a function called "def getData", which obtains through the DataLoader images in a folder on the computer and stores them in a dataframe by the Pandas library. The images are already separated into test and training sets and must be stored in the "test_data" and "train_data" variables. The images are 640 x 480 in size.
2. It must contain a function called "def getLabels", which will get lines from a file with extension ".csv", in which each line is a label of each image obtained by the "getData" function. Images and labels are defined by an already identified id. The Labels are already separated into test and training sets and must be stored in the "test_labels" and "train_labels" variables, corresponding to each image;
3. the classes forming the neural network by itself "class NetworkCNN" , it is composed of 3 convolutional layers, a pooling layer and a dropout layer, with 2 final layers of Fully Connected type (all with forward step);
4. the training function defined by "def fit(model, criterion, optimizer, train_loader, test_loader, num_epochs)" which must iterate through the images of "train_data" and "train_label" applying a step forward, a loss function (by criterion ), a step optimizer and a backward loss, in addition to updating the loss. In addition, the function must assemble a test model, iterating through the test dataset looking for the labels' predictions with a calculated accuracy. The initial image is sized 640 x 480, it must be scaled down;
5. The fit function call must be in the format: model = NetworkCNN(), with the criterion to be defined (cost/loss function), learning rate of 0.001 and Adam optimizer. Finally, the model must be trained and then tested. Number of epochs of 20.

At the end, plot the result of the cost function with the matplotlib library by number of epochs.

@author: andres
@author: Felipe-Tommaselli
"""

import os
import pandas as pd
import torch
import numpy as np
import matplotlib.pyplot as plt
from statistics import mean
#from torchvision.io import read_image
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader, random_split

from dataloader import *


def valid_imshow_data(data):
    data = np.asarray(data)
    if data.ndim == 2:
        return True
    elif data.ndim == 3:
        if 3 <= data.shape[2] <= 4:
            return True
        else:
            print('The "data" has 3 dimensions but the last dimension '
                    'must have a length of 3 (RGB) or 4 (RGBA), not "{}".'
                    ''.format(data.shape[2]))
            return False
    else:
        print('To visualize an image the data must be 2 dimensional or '
                '3 dimensional, not "{}".'
                ''.format(data.ndim))
        return False



def getData(img_path, csv_path, batch_size=10, num_workers=0):
    ''' get images from the folder (assets/images) and return a DataLoader object '''
    train_data = DataLoader(LidarDatasetCNN(img_path, csv_path, train=True), batch_size=batch_size, shuffle=True,num_workers=num_workers)
    test_data = DataLoader(LidarDatasetCNN(img_path, csv_path, train=False), batch_size=batch_size, shuffle=True,num_workers=num_workers)

    print('-'*50)
    # print the size of the dataset
    print('Train data size: ', len(train_data))
    print('loader', len(train_data.dataset))

    # print the first batch
    print('next batch:', next(iter(train_data))['image'][0].shape)
    batch = next(iter(train_data))
    images, labels = batch['image'], batch['labels']
    print('labels:', labels)

    # print the dataset    
    for i, data in enumerate(train_data):
        d = (item.type(torch.float32) for item in data)
    print('d:',  data)
    print('i: ', i)
    

    # print the first image
    img = images[0]
    valid_imshow_data(img)
    plt.imshow(img.numpy().squeeze(), cmap="gray")
    plt.show()
    print('-'*50)

    return train_data, labels

class NetworkCNN(nn.Module):
    def __init__(self):
        super(NetworkCNN, self).__init__()

        # input image: 650x650

        # 1 input image, 32 output, 3x3 convs
        self.cnn1 = nn.Conv2d(in_channels=1, out_channels= 32, kernel_size=3, stride=1, padding=0)
        # 32 input image, 64 output, 3x3 convs
        self.cnn2 = nn.Conv2d(in_channels=32, out_channels= 64, kernel_size=3, stride=1, padding=0)
        # 64 input image, 128 output, 3x3 convs
        self.cnn3 = nn.Conv2d(in_channels=64, out_channels= 128, kernel_size=3, stride=1, padding=0)
        # fully connected (128 * 3 * 3 -> 128)
        self.fc1 = nn.Linear(128 * 5 * 5, 128) #! might need to change this
        # fully connected (128 -> 10)
        self.fc2 = nn.Linear(128, 10)


    def forward(self, x):
        x = F.relu(self.cnn1(x)) # first layer conv + ReLU
        x = F.max_pool2d(x, kernel_size=3, stride=2) # Max pooling over a (3, 3) window with stride 2
        x = F.relu(self.cnn2(x)) # segunda layer conv + ReLU
        x = F.max_pool2d(x, kernel_size=3, stride=1) # Max pooling over a (3, 3) window with stride 1
        x = F.relu(self.cnn3(x)) # terceira layer conv + ReLU
        x = F.max_pool2d(x, kernel_size=2, stride=1) # Max pooling over a (2, 2) window with stride 1
        x = torch.flatten(x, 1) # compress the image to a vector
        x = self.fc1(x) # first layer fully connected
        x = self.fc2(x) # segunda layer fully connected

        return x

def fit(model, criterion, optimizer, train_loader, test_loader, num_epochs):
    model.to(device)
    
    train_losses = []
    test_losses = []

    accuracy_list = []
    predictions_list = []
    labels_list = []

    for epoch in range(num_epochs):
        running_loss = 0

        for i, data in enumerate(train_loader):
            # Transfering images and labels to GPU if available
            d = (item.type(torch.float32) for item in data)
            print('d:',  data)
            print('i: ', i)
            images, labels = data['image'], data['labels']

            print('images:', images)
            print('images type:', type(images))
            images = images.to(device) #! without labels to device (not a tensor)

            outputs = model.forward(images)  # frontward propagation
            loss = criterion(outputs, labels) 
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

        else:
        # Testing the model
            with torch.no_grad():
                # Set the model to evaluation mode
                model.eval()

                total = 0
                test_loss = 0
                correct = 0

                for images, labels in test_loader:
                    images, labels = images.to(device), labels.to(device)
                    labels_list.append(labels)
                    total += len(labels)
                    
                    outputs = model.forward(images) # propagação para frente
                    
                    
                    predictions = torch.max(outputs, 1)[1].to(device)
                    predictions_list.append(predictions)
                    correct += (predictions == labels).sum()

                    test_loss += criterion(outputs, labels).item()
                test_losses.append(test_loss/len(test_loader))

                accuracy = correct * 100 / total
                accuracy_list.append(accuracy.item())
            

            # Set the model to training mode
            model.train()
        
        train_losses.append(running_loss/len(train_loader))

        print(f'Epoch {epoch+1}/{num_epochs} .. Train Loss: {train_losses[-1]:.5f} .. Test Loss: {test_losses[-1]:.5f} .. Test Accuracy: {accuracy_list[-1]:.3f}%')

            
    results = {
        'train_losses': train_losses,
        'test_losses': test_losses,
        'accuracy_list': accuracy_list
    }
    
    return results

def plotResults(results):
    plt.plot(results['train_losses'], label='Training loss')
    plt.plot(results['test_losses'], label='Validation loss')
    plt.legend(frameon=False)
    plt.show()

    plt.plot(results['accuracy_list'], label='Accuracy')
    plt.legend(frameon=False)
    plt.show()

if __name__ == '__main__':
    # Set the device to GPU if available
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print('Using {} device'.format(device))

    # Get the data
    train_data, labels = getData(img_path="~/Documents/IC_NN_Lidar/assets/classified/image", csv_path="~/Documents/IC_NN_Lidar/assets/tags/Label_Data.csv")

    # Create the model
    model = NetworkCNN()
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

    # Train the model
    #! without test data yet 
    results = fit(model=model, criterion=criterion, optimizer=optimizer, train_loader=train_data, test_loader=train_data, num_epochs=10)

    plotResults(results)

    # Save the model
    torch.save(model.state_dict(), 'model.pth')
    print('Saved PyTorch Model State to model.pth')

    #* not there yet

    # # Load the model
    # model = NetworkCNN()
    # model.load_state_dict(torch.load('model.pth'))

    # # Test the model
    # with torch.no_grad():
    #     # Set the model to evaluation mode
    #     model.eval()

    #     total = 0
    #     correct = 0

    #     for images, labels in test_data:
    #         images, labels = images.to(device), labels.to(device)
    #         outputs = model.forward(images)
    #         predictions = torch.max(outputs, 1)[1].to(device)
    #         correct += (predictions == labels).sum()
    #         total += len(labels)

    #     print(f'Accuracy of the network on the 10000 test images: {correct * 100 / total}%')

    # # Test the model with a single image
    # with torch.no_grad():
    #     # Set the model to evaluation mode
    #     model.eval()

    #     image = test_data[0][0].to(device)
    #     label = test_data[0][1].to(device)

    #     output = model.forward(image)
    #     prediction = torch.max(output, 0)[1].to(device)

    #     print(f'Prediction of the network on the first image: {prediction}')
    #     print(f'Label of the first image: {label}')

    # # plot results of the test
    # plt.imshow(image.cpu().numpy().squeeze(), cmap='gray_r')
    # plt.show()