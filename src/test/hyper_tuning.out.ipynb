{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "884d3528",
   "metadata": {},
   "source": [
    "# DEPRECATED\n",
    "\n",
    "This notebook is deprecated. The Hyper tuning feature is no longer necessary. The main idea of this notebook was to auto tuning the parameters of the model, but with the current implementation, the hand tests are enough to get a good score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5551bf95",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "from datetime import datetime\n",
    "from artificial_dataloader import *\n",
    "from pre_process import *\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd22b18",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getData(csv_path, train_path, batch_size, num_workers=0):\n",
    "    ''' get images from the folder (assets/images) and return a DataLoader object '''\n",
    "    \n",
    "    dataset = ArtificialLidarDatasetCNN(csv_path, train_path)\n",
    "\n",
    "    print(f'dataset size (no augmentation): {len(dataset)}')\n",
    "    #! artificial não se beneficia muito disso\n",
    "    # dataset = transformData(dataset)\n",
    "    print(f'dataset size (w/ augmentation): {len(dataset)}')\n",
    "\n",
    "    train_size, val_size = int(0.8*len(dataset)), np.ceil(0.2*len(dataset)).astype('int')\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    train_data = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=num_workers)\n",
    "    val_data  = DataLoader(val_dataset, batch_size=batch_size, shuffle=True,num_workers=num_workers)\n",
    "\n",
    "    print(f'train size: {train_size}, val size: {val_size}')\n",
    "    return train_data, val_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35998e7e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs):\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    predictions_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "            images, labels = data['image'], data['labels']\n",
    "            # convert to float32 and send it to the device\n",
    "            # image dimension: (batch, channels, height, width)\n",
    "            images = images.type(torch.float32).to(device)\n",
    "            images = images.unsqueeze(1)\n",
    "            # convert labels to float32 and send it to the device\n",
    "            labels = [label.type(torch.float32).to(device) for label in labels]\n",
    "            # convert labels to tensor\n",
    "            labels = torch.stack(labels)\n",
    "            # convert to format: tensor([[value1, value2, value3, value4], [value1, value2, value3, value4], ...])\n",
    "            # this is: labels for each image, \"batch\" times -> shape: (batch, 4)\n",
    "            labels = labels.permute(1, 0)    \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels) \n",
    "            # Loss_with_L2 = Loss_without_L2 + λ * ||w||^2\n",
    "            # Calculate L2 regularization loss\n",
    "            l2_regularization_loss = 0\n",
    "            for param in model.parameters():\n",
    "                l2_regularization_loss += torch.norm(param, 2)\n",
    "            loss += weight_decay * l2_regularization_loss  # Add L2 regularization loss to the total loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            running_loss += loss.item()\n",
    "        else:\n",
    "        # valing the model\n",
    "            with torch.no_grad():\n",
    "                # Set the model to evaluation mode\n",
    "                model.eval()\n",
    "                total = 0\n",
    "                val_loss = 0\n",
    "                for i, data in enumerate(val_loader):\n",
    "                    images, labels = data['image'], data['labels']\n",
    "                    # image dimension: (batch, channels, height, width)\n",
    "                    images = images.type(torch.float32).to(device)\n",
    "                    images = images.unsqueeze(1)\n",
    "                    labels = [label.type(torch.float32).to(device) for label in labels]\n",
    "                    labels = torch.stack(labels)\n",
    "                    labels = labels.permute(1, 0)\n",
    "                    labels_list.append(labels)\n",
    "                    total += len(labels)\n",
    "                    outputs = model.forward(images) # propagação para frente\n",
    "                    # get the predictions to calculate the accuracy\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    val_loss += criterion(outputs, labels).item()\n",
    "                val_losses.append(val_loss/len(val_loader))\n",
    "            pass\n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        val_losses.append(running_loss/len(val_loader))\n",
    "        print(f'[{epoch+1}/{num_epochs}] .. Train Loss: {train_losses[-1]:.5f} .. val Loss: {val_losses[-1]:.5f}')\n",
    "\n",
    "\n",
    "    results = {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d15340",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Função objetivo para otimizar a taxa de aprendizado (lr)\n",
    "def objective(lr):\n",
    "\n",
    "    ############ HYPER PARAMS ############\n",
    "    epochs = 12\n",
    "    step_size = 3\n",
    "    gamma = 0.5\n",
    "    batch_size = 160\n",
    "    weight_decay = 1e-4\n",
    "\n",
    "    ############ DATA ############\n",
    "    csv_path = \"../../artificial_data/tags/Artificial_Label_Data3.csv\"\n",
    "    # train_path = os.getcwd() + SLASH + 'artificial_data' + SLASH + 'train4' + SLASH\n",
    "    train_path = os.path.join(os.getcwd(), '..', '..', 'artificial_data', 'train3')\n",
    "    train_data, val_data = getData(batch_size=batch_size, csv_path=csv_path, train_path=train_path)\n",
    "\n",
    "    ############ MODEL ############\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(num_ftrs, 512),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.BatchNorm1d(256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(256, 3)\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "    # Realize o treinamento do modelo\n",
    "    results = train_model(model, criterion, optimizer, scheduler, train_data, val_data, epochs)\n",
    "\n",
    "    # Retorne a métrica de desempenho que você deseja otimizar (por exemplo, perda mínima)\n",
    "    # Neste exemplo, estamos considerando a última perda de validação\n",
    "    return results['val_losses'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974cf492",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crie o espaço de busca para a taxa de aprendizado (lr)\n",
    "space = hp.uniform('lr', 1e-7, 1e-2)\n",
    "\n",
    "# Crie um objeto Trials para rastrear os resultados da otimização\n",
    "trials = Trials()\n",
    "\n",
    "# Realize a otimização usando o TPE (Tree-structured Parzen Estimator)\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=50, trials=trials)\n",
    "\n",
    "# O melhor valor de lr será armazenado em best['lr']\n",
    "best_lr = best['lr']\n",
    "print(\"Melhor valor de lr encontrado:\", best_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 0.069017,
   "end_time": "2023-10-28T02:16:05.026129",
   "environment_variables": {},
   "exception": null,
   "input_path": "hyper_tuning.ipynb",
   "output_path": "logs/hyper_tuning.out.ipynb",
   "parameters": {},
   "start_time": "2023-10-28T02:16:04.957112",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
