{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import torchvision.models as models\n",
    "print(os.getcwd())\n",
    "os.chdir('..')\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@159.577] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('data/gazebo_data/train1/image0.png'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "# open image with cv2 from folder: data/gazebo_data/train1/image0.png\n",
    "image = cv2.imread(os.path.join(\"data\", \"gazebo_data\", \"train1\", \"image0.png\"))\n",
    "# convert image to numpy \n",
    "image = np.array(image)\n",
    "\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/tommaselli/models/model_005_17-01-2024_15-38-12.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mclassifier[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m      8\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(num_ftrs, \u001b[38;5;241m512\u001b[39m),\n\u001b[1;32m      9\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBatchNorm1d(\u001b[38;5;241m512\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/models/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_005_17-01-2024_15-38-12.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 18\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Load to CPU\u001b[39;00m\n\u001b[1;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint)\n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/tommaselli/models/model_005_17-01-2024_15-38-12.pth'"
     ]
    }
   ],
   "source": [
    "########### MOBILE NET ########### \n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "model.features[0][0] = torch.nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "\n",
    "# MobileNetV2 uses a different attribute for the classifier\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = torch.nn.Sequential(\n",
    "torch.nn.Linear(num_ftrs, 512),\n",
    "torch.nn.BatchNorm1d(512),\n",
    "torch.nn.ReLU(inplace=True),\n",
    "torch.nn.Linear(512, 256),\n",
    "torch.nn.BatchNorm1d(256),\n",
    "torch.nn.ReLU(inplace=True),\n",
    "torch.nn.Linear(256, 3)\n",
    ")\n",
    "\n",
    "path = os.getcwd() + '/models/' + 'model_005_17-01-2024_15-38-12.pth'\n",
    "checkpoint = torch.load(path, map_location='cpu')  # Load to CPU\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicie a contagem de tempo antes da inferência\n",
    "start_time = time.time()\n",
    "\n",
    "# get the model predictions\n",
    "predictions = model(image)\n",
    "\n",
    "# Encerre a contagem de tempo após a inferência\n",
    "end_time = time.time()\n",
    "\n",
    "print('Inference time: {:.4f} ms'.format((end_time - start_time)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess(image, label):\n",
    "    ''' Returns the deprocessed image and label. '''\n",
    "\n",
    "    if len(label) == 3:\n",
    "        # we suppose m1 = m2, so we can use the same deprocess\n",
    "        print('supposing m1 = m2')   \n",
    "        w1, q1, q2 = label\n",
    "        w2 = w1\n",
    "    elif len(label) == 4:\n",
    "        print('not supposing m1 = m2')        \n",
    "        w1, w2, q1, q2 = label\n",
    "\n",
    "    # DEPROCESS THE LABEL\n",
    "    q1_original = ((q1 + 1) * (187.15 - (-56.06)) / 2) + (-56.06)\n",
    "    q2_original = ((q2 + 1) * (299.99 - 36.81) / 2) + 36.81\n",
    "    w1_original = ((w1 + 1) * (0.58 - (-0.58)) / 2) + (-0.58)\n",
    "    w2_original = ((w2 + 1) * (0.58 - (-0.58)) / 2) + (-0.58)\n",
    "\n",
    "\n",
    "    # print(f'labels w1={w1}, w2={w2}, q1={q1}, q2={q2}')\n",
    "    m1, m2, b1, b2 = PreProcess.parametrization(w1_original, w2_original, q1_original, q2_original)\n",
    "\n",
    "    label = [m1, m2, b1, b2]\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the predictions to numpy array\n",
    "predictions = predictions.to('cpu').cpu().detach().numpy()\n",
    "predictions = PreProcess.deprocess(image=image, label=predictions[0].tolist())\n",
    "\n",
    "\n",
    "# convert image to cpu \n",
    "image = image.to('cpu').cpu().detach().numpy()\n",
    "# image it is shape (1, 1, 507, 507), we need to remove the first dimension\n",
    "image = image[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5), frameon=True)\n",
    "\n",
    "linewidth = 2.5\n",
    "\n",
    "ax.plot(x, y1p, color='red', label='Predicted', linewidth=linewidth)\n",
    "ax.plot(x, y2p, color='red', linewidth=linewidth)\n",
    "\n",
    "# Customize the title\n",
    "# title_font = {'family': 'Ubuntu', 'color': 'black', 'weight': 'bold', 'size': 18}\n",
    "# plt.title('Inference Results', fontdict=title_font)\n",
    "\n",
    "# Add a white rectangle to create a border\n",
    "border_style = dict(facecolor='none', edgecolor='black', linewidth=2)\n",
    "ax.add_patch(plt.Rectangle((0, 0), 1, 1, **border_style, transform=ax.transAxes))\n",
    "\n",
    "# legend\n",
    "plt.legend(loc='upper right', prop={'size': 9, 'family': 'Ubuntu'})\n",
    "\n",
    "# show the image\n",
    "im = ax.imshow(image, cmap='magma', norm=PowerNorm(gamma=16), alpha=0.65)\n",
    "ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
